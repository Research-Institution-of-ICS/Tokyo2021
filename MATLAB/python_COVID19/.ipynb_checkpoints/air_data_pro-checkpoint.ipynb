{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#引入漂亮汤\n",
    "from bs4 import BeautifulSoup\n",
    "#引入requests包，发送http请求\n",
    "import requests\n",
    "#引入xlwt包，写入excel文件\n",
    "import xlwt \n",
    "#引入xl包，用来读取excel文件\n",
    "\n",
    "import xlrd\n",
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-22\n",
      "2018-08-23\n",
      "2018-08-24\n",
      "2018-08-25\n",
      "2018-08-26\n",
      "2018-08-27\n",
      "2018-08-28\n",
      "2018-08-29\n",
      "2018-08-30\n",
      "2018-08-31\n",
      "2018-09-01\n",
      "2018-09-02\n",
      "2018-09-03\n",
      "2018-09-04\n",
      "2018-09-05\n",
      "2018-09-06\n",
      "2018-09-07\n",
      "2018-09-08\n",
      "2018-09-09\n",
      "2018-09-10\n",
      "2018-09-11\n",
      "2018-09-12\n",
      "2018-09-13\n",
      "2018-09-14\n",
      "2018-09-15\n",
      "2018-09-16\n",
      "2018-09-17\n",
      "2018-09-18\n",
      "2018-09-19\n",
      "2018-09-20\n",
      "2018-09-21\n",
      "2018-09-22\n",
      "2018-09-23\n",
      "2018-09-24\n",
      "2018-09-25\n",
      "2018-09-26\n",
      "2018-09-27\n",
      "2018-09-28\n",
      "2018-09-29\n",
      "2018-09-30\n",
      "2018-10-01\n",
      "2018-10-02\n",
      "2018-10-03\n",
      "2018-10-04\n",
      "2018-10-05\n",
      "2018-10-06\n",
      "2018-10-07\n",
      "2018-10-08\n",
      "2018-10-09\n",
      "2018-10-10\n",
      "2018-10-11\n",
      "2018-10-12\n",
      "2018-10-13\n",
      "2018-10-14\n",
      "2018-10-15\n",
      "2018-10-16\n",
      "2018-10-17\n",
      "2018-10-18\n",
      "2018-10-19\n",
      "2018-10-20\n",
      "2018-10-21\n",
      "2018-10-22\n",
      "2018-10-23\n",
      "2018-10-24\n",
      "2018-10-25\n",
      "2018-10-26\n",
      "2018-10-27\n",
      "2018-10-28\n",
      "2018-10-29\n",
      "2018-10-30\n",
      "2018-10-31\n",
      "2018-11-01\n",
      "2018-11-02\n",
      "2018-11-03\n",
      "2018-11-04\n",
      "2018-11-05\n",
      "2018-11-06\n",
      "2018-11-07\n",
      "2018-11-08\n",
      "2018-11-09\n",
      "2018-11-10\n",
      "2018-11-11\n",
      "2018-11-12\n",
      "2018-11-13\n",
      "2018-11-14\n",
      "2018-11-15\n",
      "2018-11-16\n",
      "2018-11-17\n",
      "2018-11-18\n",
      "2018-11-19\n",
      "2018-11-20\n",
      "2018-11-21\n",
      "2018-11-22\n",
      "2018-11-23\n",
      "2018-11-24\n",
      "2018-11-25\n",
      "2018-11-26\n",
      "2018-11-27\n",
      "2018-11-28\n",
      "2018-11-29\n",
      "2018-11-30\n",
      "2018-12-01\n",
      "2018-12-02\n",
      "2018-12-03\n",
      "2018-12-04\n",
      "2018-12-05\n",
      "2018-12-06\n",
      "2018-12-07\n",
      "2018-12-08\n",
      "2018-12-09\n",
      "2018-12-10\n",
      "2018-12-11\n",
      "2018-12-12\n",
      "2018-12-13\n",
      "2018-12-14\n",
      "2018-12-15\n",
      "2018-12-16\n",
      "2018-12-17\n",
      "2018-12-18\n",
      "2018-12-19\n",
      "2018-12-20\n",
      "2018-12-21\n",
      "2018-12-22\n",
      "2018-12-23\n",
      "2018-12-24\n",
      "2018-12-25\n",
      "2018-12-26\n",
      "2018-12-27\n",
      "2018-12-28\n",
      "2018-12-29\n",
      "2018-12-30\n",
      "2018-12-31\n",
      "2019-01-01\n",
      "2019-01-02\n",
      "2019-01-03\n",
      "2019-01-04\n",
      "2019-01-05\n",
      "2019-01-06\n",
      "2019-01-07\n",
      "2019-01-08\n",
      "2019-01-09\n",
      "2019-01-10\n",
      "2019-01-11\n",
      "2019-01-12\n",
      "2019-01-13\n",
      "2019-01-14\n",
      "2019-01-15\n",
      "2019-01-16\n",
      "2019-01-17\n",
      "2019-01-18\n",
      "2019-01-19\n",
      "2019-01-20\n",
      "2019-01-21\n",
      "2019-01-22\n",
      "2019-01-23\n",
      "2019-01-24\n",
      "2019-01-25\n",
      "2019-01-26\n",
      "2019-01-27\n",
      "2019-01-28\n",
      "2019-01-29\n",
      "2019-01-30\n",
      "2019-01-31\n",
      "2019-02-01\n",
      "2019-02-02\n",
      "2019-02-03\n",
      "2019-02-04\n",
      "2019-02-05\n",
      "2019-02-06\n",
      "2019-02-07\n",
      "2019-02-08\n",
      "2019-02-09\n",
      "2019-02-10\n",
      "2019-02-11\n",
      "2019-02-12\n",
      "2019-02-13\n",
      "2019-02-14\n",
      "2019-02-15\n",
      "2019-02-16\n",
      "2019-02-17\n",
      "2019-02-18\n",
      "2019-02-19\n",
      "2019-02-20\n",
      "2019-02-21\n",
      "2019-02-22\n",
      "2019-02-23\n",
      "2019-02-24\n",
      "2019-02-25\n",
      "2019-02-26\n",
      "2019-02-27\n",
      "2019-02-28\n",
      "2019-03-01\n",
      "2019-03-02\n",
      "2019-03-03\n",
      "2019-03-04\n",
      "2019-03-05\n",
      "2019-03-06\n",
      "2019-03-07\n",
      "2019-03-08\n",
      "2019-03-09\n",
      "2019-03-10\n",
      "2019-03-11\n",
      "2019-03-12\n",
      "2019-03-13\n",
      "2019-03-14\n",
      "2019-03-15\n",
      "2019-03-16\n",
      "2019-03-17\n",
      "2019-03-18\n",
      "2019-03-19\n",
      "2019-03-20\n",
      "2019-03-21\n",
      "2019-03-22\n",
      "2019-03-23\n",
      "2019-03-24\n",
      "2019-03-25\n",
      "2019-03-26\n",
      "2019-03-27\n",
      "2019-03-28\n",
      "2019-03-29\n",
      "2019-03-30\n",
      "2019-03-31\n",
      "2019-04-01\n",
      "2019-04-02\n",
      "2019-04-03\n",
      "2019-04-04\n",
      "2019-04-05\n",
      "2019-04-06\n",
      "2019-04-07\n",
      "2019-04-08\n",
      "2019-04-09\n",
      "2019-04-10\n",
      "2019-04-11\n",
      "2019-04-12\n",
      "2019-04-13\n",
      "2019-04-14\n",
      "2019-04-15\n",
      "2019-04-16\n",
      "2019-04-17\n",
      "2019-04-18\n",
      "2019-04-19\n",
      "2019-04-20\n",
      "2019-04-21\n",
      "2019-04-22\n",
      "2019-04-23\n",
      "2019-04-24\n",
      "2019-04-25\n",
      "2019-04-26\n",
      "2019-04-27\n",
      "2019-04-28\n",
      "2019-04-29\n",
      "2019-04-30\n",
      "2019-05-01\n",
      "2019-05-02\n",
      "2019-05-03\n",
      "2019-05-04\n",
      "2019-05-05\n",
      "2019-05-06\n",
      "2019-05-07\n",
      "2019-05-08\n",
      "2019-05-09\n",
      "2019-05-10\n",
      "2019-05-11\n",
      "2019-05-12\n",
      "2019-05-13\n",
      "2019-05-14\n",
      "2019-05-15\n",
      "2019-05-16\n",
      "2019-05-17\n",
      "2019-05-18\n",
      "2019-05-19\n",
      "2019-05-20\n",
      "2019-05-21\n",
      "2019-05-22\n",
      "2019-05-23\n",
      "2019-05-24\n",
      "2019-05-25\n",
      "2019-05-26\n",
      "2019-05-27\n",
      "2019-05-28\n",
      "2019-05-29\n",
      "2019-05-30\n",
      "2019-05-31\n",
      "2019-06-01\n",
      "2019-06-02\n",
      "2019-06-03\n",
      "2019-06-04\n",
      "2019-06-05\n",
      "2019-06-06\n",
      "2019-06-07\n",
      "2019-06-08\n",
      "2019-06-09\n",
      "2019-06-10\n",
      "2019-06-11\n",
      "2019-06-12\n",
      "2019-06-13\n",
      "2019-06-14\n",
      "2019-06-15\n",
      "2019-06-16\n",
      "2019-06-17\n",
      "2019-06-18\n",
      "2019-06-19\n",
      "2019-06-20\n",
      "2019-06-21\n",
      "2019-06-22\n",
      "2019-06-23\n",
      "2019-06-24\n",
      "2019-06-25\n",
      "2019-06-26\n",
      "2019-06-27\n",
      "2019-06-28\n",
      "2019-06-29\n",
      "2019-06-30\n",
      "2019-07-01\n",
      "2019-07-02\n",
      "2019-07-03\n",
      "2019-07-04\n",
      "2019-07-05\n",
      "2019-07-06\n",
      "2019-07-07\n",
      "2019-07-08\n",
      "2019-07-09\n",
      "2019-07-10\n",
      "2019-07-11\n",
      "2019-07-12\n",
      "2019-07-13\n",
      "2019-07-14\n",
      "2019-07-15\n",
      "2019-07-16\n",
      "2019-07-17\n",
      "2019-07-18\n",
      "2019-07-19\n",
      "2019-07-20\n",
      "2019-07-21\n",
      "2019-07-22\n",
      "2019-07-23\n",
      "2019-07-24\n",
      "2019-07-25\n",
      "2019-07-26\n",
      "2019-07-27\n",
      "2019-07-28\n",
      "2019-07-29\n",
      "2019-07-30\n",
      "2019-07-31\n",
      "2019-08-01\n",
      "2019-08-02\n",
      "2019-08-03\n",
      "2019-08-04\n",
      "2019-08-05\n",
      "2019-08-06\n",
      "2019-08-07\n",
      "2019-08-08\n",
      "2019-08-09\n",
      "2019-08-10\n",
      "2019-08-11\n",
      "2019-08-12\n",
      "2019-08-13\n",
      "2019-08-14\n",
      "2019-08-15\n",
      "2019-08-16\n",
      "2019-08-17\n",
      "2019-08-18\n",
      "2019-08-19\n",
      "2019-08-20\n",
      "2019-08-21\n"
     ]
    }
   ],
   "source": [
    "file = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\2019\\2018_2019.csv', usecols=[0,1, 2,3])\n",
    "groups = file.groupby(file[u'Time series'])\n",
    "count = 0 \n",
    "for group in groups:\n",
    "    print(group[0])\n",
    "    path = r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\2019\\date series\\\\'+ str(count) + '.csv'\n",
    "    group[1].to_csv(path, index = 0)\n",
    "    count += 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "file1 = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\new_airports.csv', usecols=['iata_code'])\n",
    "for j in range(1):\n",
    "    count = []\n",
    "    flight = np.zeros((len(file1), len(file1)))\n",
    "    file2 = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\2017\\basic data\\\\'+str(j)+'.csv', usecols=[0,1,2])\n",
    "    file2 = pd.DataFrame(file2)\n",
    "    for i in range(len(file2)):\n",
    "        take_off_city  = file2.loc[i][0]\n",
    "        down_city = file2.loc[i][1]\n",
    "        number = file2.loc[i][2]\n",
    "        #print(i)\n",
    "        a = file1[file1['iata_code'].isin([take_off_city])].index.tolist()\n",
    "        b = file1[file1['iata_code'].isin([down_city])].index.tolist()\n",
    "        if a == [] or b == []:\n",
    "            temp = file2.iloc[i]\n",
    "            count.append(temp)\n",
    "            continue;\n",
    "        else:\n",
    "            a = a[0]\n",
    "            b = b[0]\n",
    "        flight[a][b] += number\n",
    "    flight = pd.DataFrame(flight,columns = file1['iata_code'])\n",
    "    flight.to_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\2017\\array\\code_array\\code'+str(j)+'.csv',index=0)\n",
    "    count = pd.DataFrame(count)\n",
    "    count.to_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\2017\\array\\loss_data\\loss'+str(j)+'.csv',index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理机场数据\n",
    "index = [2016, 2017, 2018, 2019]\n",
    "c = ['PVG']\n",
    "for i in index:\n",
    "    a = pd.read_csv(r'F:/项目/新冠肺炎/参考论文/2016_flight/newdata\\\\'+str(i) + '.csv', usecols=[0])\n",
    "    b = pd.read_csv(r'F:/项目/新冠肺炎/参考论文/2016_flight/newdata\\\\'+str(i) + '.csv', usecols=[1])\n",
    "    temp = np.vstack((a,b))\n",
    "    c = np.vstack((temp,c))\n",
    "#   c = np.unique(c)\n",
    "print(len(c)) \n",
    "c = np.unique(c)\n",
    "print(len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\airports.csv',usecols=[12,1,2,3,4,6,7,8])\n",
    "new_airports = airports.loc[airports['iata_code'].isin(c)]\n",
    "print(len(airports))\n",
    "print(len(new_airports))\n",
    "print(new_airports)\n",
    "new_airports.to_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\new_airports1.csv', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "file1 = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\new_airports.csv', usecols=['iata_code'])\n",
    "for j in range(60):\n",
    "    count = []\n",
    "    flight = np.zeros((len(file1), len(file1)))\n",
    "    file2 = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\2017\\basic data\\\\'+str(j)+'.csv', usecols=[0,1,2])\n",
    "    file2 = pd.DataFrame(file2)\n",
    "    for i in range(len(file2)):\n",
    "        take_off_city  = file2.loc[i][0]\n",
    "        down_city = file2.loc[i][1]\n",
    "        number = file2.loc[i][2]\n",
    "        #print(i)\n",
    "        a = file1[file1['iata_code'].isin([take_off_city])].index.tolist()\n",
    "        b = file1[file1['iata_code'].isin([down_city])].index.tolist()\n",
    "        if a == [] or b == []:\n",
    "            temp = file2.iloc[i]\n",
    "            count.append(temp)\n",
    "            continue;\n",
    "        else:\n",
    "            a = a[0]\n",
    "            b = b[0]\n",
    "        flight[a][b] += number\n",
    "    flight = pd.DataFrame(flight,columns = file1['iata_code'])\n",
    "    flight.to_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\2017\\array\\code_array\\code'+str(j)+'.csv',index=0)\n",
    "    count = pd.DataFrame(count)\n",
    "    count.to_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\2017\\array\\loss_data\\loss'+str(j)+'.csv',index=0)\n",
    "\n",
    "file1 = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\new_airports.csv', usecols=['iata_code'])\n",
    "for j in range(60):\n",
    "    count = []\n",
    "    flight = np.zeros((len(file1), len(file1)))\n",
    "    file2 = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\2018\\basic data\\\\'+str(j)+'.csv', usecols=[0,1,2])\n",
    "    file2 = pd.DataFrame(file2)\n",
    "    for i in range(len(file2)):\n",
    "        take_off_city  = file2.loc[i][0]\n",
    "        down_city = file2.loc[i][1]\n",
    "        number = file2.loc[i][2]\n",
    "        #print(i)\n",
    "        a = file1[file1['iata_code'].isin([take_off_city])].index.tolist()\n",
    "        b = file1[file1['iata_code'].isin([down_city])].index.tolist()\n",
    "        if a == [] or b == []:\n",
    "            temp = file2.iloc[i]\n",
    "            count.append(temp)\n",
    "            continue;\n",
    "        else:\n",
    "            a = a[0]\n",
    "            b = b[0]\n",
    "        flight[a][b] += number\n",
    "    flight = pd.DataFrame(flight,columns = file1['iata_code'])\n",
    "    flight.to_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\2018\\array\\code_array\\code'+str(j)+'.csv',index=0)\n",
    "    count = pd.DataFrame(count)\n",
    "    count.to_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\2018\\array\\loss_data\\loss'+str(j)+'.csv',index=0)\n",
    "\n",
    "\n",
    "file1 = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\new_airports.csv', usecols=['iata_code'])\n",
    "for j in range(60):\n",
    "    count = []\n",
    "    flight = np.zeros((len(file1), len(file1)))\n",
    "    file2 = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\2019\\basic data\\\\'+str(j)+'.csv', usecols=[0,1,2])\n",
    "    file2 = pd.DataFrame(file2)\n",
    "    for i in range(len(file2)):\n",
    "        take_off_city  = file2.loc[i][0]\n",
    "        down_city = file2.loc[i][1]\n",
    "        number = file2.loc[i][2]\n",
    "        #print(i)\n",
    "        a = file1[file1['iata_code'].isin([take_off_city])].index.tolist()\n",
    "        b = file1[file1['iata_code'].isin([down_city])].index.tolist()\n",
    "        if a == [] or b == []:\n",
    "            temp = file2.iloc[i]\n",
    "            count.append(temp)\n",
    "            continue;\n",
    "        else:\n",
    "            a = a[0]\n",
    "            b = b[0]\n",
    "        flight[a][b] += number\n",
    "    flight = pd.DataFrame(flight,columns = file1['iata_code'])\n",
    "    flight.to_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\2019\\array\\code_array\\code'+str(j)+'.csv',index=0)\n",
    "    count = pd.DataFrame(count)\n",
    "    count.to_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\2019\\array\\loss_data\\loss'+str(j)+'.csv',index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\new_airports.csv',usecols=[1,5]) \n",
    "name = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\new_airports.csv', usecols=['iso_country'])\n",
    "name = np.unique(name)\n",
    "group = country.groupby('iso_country')\n",
    "number = group.size().values\n",
    "for j in range(60):\n",
    "    print(j)\n",
    "    data1 = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\2019\\array\\code_array\\\\'+'code'+str(j)+'.csv').values\n",
    "    count = 0 \n",
    "    for i in range(len(number)):\n",
    "        if number[i] == 1 :\n",
    "            count += number[i]\n",
    "            continue;\n",
    "        if i == 0:\n",
    "            data1[:, 0] += sum(data1[:, 0:number[i]].T)\n",
    "            data1[0, :] += sum(data1[0:number[i], :])\n",
    "        else:\n",
    "            data1[:, count] += sum(data1[:, count:count+number[i]].T)\n",
    "            data1[count, :] += sum(data1[count:count+number[i], :])\n",
    "        count += number[i]\n",
    "    data2 = data1\n",
    "    count = 0 \n",
    "    a = []\n",
    "    for i in range(len(number)):\n",
    "        if number[i] == 1 :\n",
    "            count += number[i]\n",
    "            continue; \n",
    "        a += list(range(count+1,count+number[i]))\n",
    "        count += number[i] \n",
    "    data = np.delete(data1, a, axis=1)\n",
    "    data = np.delete(data, a, axis=0)\n",
    "    print(np.shape(data))\n",
    "    data = pd.DataFrame(data ,columns = name)\n",
    "    data.to_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\2019\\array\\country_array\\\\'+'array'+str(j)+'.csv',index=0)\n",
    "    del a,data,data1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for j in range(60):\n",
    "    print(j)\n",
    "    data1 = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\2019\\array\\code_array\\\\'+'code'+str(j)+'.csv').values\n",
    "    count = 0 \n",
    "    for i in range(len(number)):\n",
    "        if number[i] == 1 :\n",
    "            count += number[i]\n",
    "            continue;\n",
    "        if i == 0:\n",
    "            data1[:, 0] += sum(data1[:, 0:number[i]].T)\n",
    "            data1[0, :] += sum(data1[0:number[i], :])\n",
    "        else:\n",
    "            data1[:, count] += sum(data1[:, count:count+number[i]].T)\n",
    "            data1[count, :] += sum(data1[count:count+number[i], :])\n",
    "        count += number[i]\n",
    "    data2 = data1\n",
    "    count = 0 \n",
    "    a = []\n",
    "    for i in range(len(number)):\n",
    "        if number[i] == 1 :\n",
    "            count += number[i]\n",
    "            continue; \n",
    "        a += list(range(count+1,count+number[i]))\n",
    "        count += number[i] \n",
    "    data = np.delete(data1, a, axis=1)\n",
    "    data = np.delete(data, a, axis=0)\n",
    "    print(np.shape(data))\n",
    "    data = pd.DataFrame(data ,columns = name)\n",
    "    data.to_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\2019\\array\\country_array\\\\'+'array'+str(j)+'.csv',index=0)\n",
    "    del a,data,data1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算日航班乘坐人数\n",
    "import numpy as np \n",
    "day_num_2016 = []\n",
    "day_num_2017 = []\n",
    "day_num_2018 = []\n",
    "day_num_2019 = []\n",
    "for i in range(60):\n",
    "    data = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\2016\\array\\country_array\\array' + str(i) + '.csv').values \n",
    "    num = np.sum(data)\n",
    "    day_num_2016.append(num)\n",
    "for i in range(60):\n",
    "    data = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\2017\\array\\country_array\\array' + str(i) + '.csv').values \n",
    "    num = np.sum(data)\n",
    "    day_num_2017.append(num)\n",
    "for i in range(60):\n",
    "    data = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\2018\\array\\country_array\\array' + str(i) + '.csv').values \n",
    "    num = np.sum(data)\n",
    "    day_num_2018.append(num)\n",
    "for i in range(60):\n",
    "    data = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\2019\\array\\country_array\\array' + str(i) + '.csv').values \n",
    "    num = np.sum(data)\n",
    "    day_num_2019.append(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame({'2016年日航空人数':day_num_2016, '2017年日航空人数':day_num_2017, '2018年日航空人数':day_num_2018,'2019年日航空人数':day_num_2019})\n",
    "dataframe.to_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\相关性数据\\num.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 画图 \n",
    "t = range(60)\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt \n",
    "zhfont1 = matplotlib.font_manager.FontProperties(fname='C:\\Windows\\Fonts\\simkai.ttf')\n",
    "plt.figure(num=1, figsize=(20, 10),dpi=80)\n",
    "plt.plot(t, day_num_2016,color = 'red',linewidth = 3.0,linestyle = '--',label = '2016')\n",
    "plt.plot(t, day_num_2017,color = 'black',linewidth = 3.0,linestyle = '-', label = '2017')\n",
    "plt.plot(t, day_num_2018,color = 'c',linewidth = 3.0,linestyle = ':',label = '2018')\n",
    "plt.plot(t, day_num_2019,color = 'g',linewidth = 3.0,linestyle = '-.',label = '2019')\n",
    "#plt.savefig(r'C:\\Users\\lenovo\\Desktop\\参考论文\\2016_flight\\相关性_时间序列\\day_num.jpg') \n",
    "plt.xlabel('时间/天',fontproperties=zhfont1)#x轴上的名字\n",
    "plt.ylabel('日航空人数',fontproperties=zhfont1)#y轴上的名字\n",
    "plt.grid(True)\n",
    "plt.legend(loc='upper left') \n",
    "# print(plt)\n",
    "plt.savefig(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\相关性数据\\day_num.jpg') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算日总量相关性\n",
    "data = [day_num_2016, day_num_2017, day_num_2018, day_num_2019]\n",
    "corr = np.corrcoef(data,rowvar=True) \n",
    "corr_data = pd.DataFrame(corr)\n",
    "corr_data.to_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\相关性数据\\corr.csv', index= 0)\n",
    "\n",
    "# 计算每天的航空客流量相关性 \n",
    "for i in range(60):\n",
    "    # 读取数据\n",
    "    data1 = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\2016\\array\\country_array\\array' + str(i) + '.csv').values \n",
    "    data2 = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\2017\\array\\country_array\\array' + str(i) + '.csv').values \n",
    "    data3 = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\2018\\array\\country_array\\array' + str(i) + '.csv').values \n",
    "    data4 = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\2019\\array\\country_array\\array' + str(i) + '.csv').values \n",
    "    # 将矩阵展成向量\n",
    "    data1 = data1.ravel()\n",
    "    data2 = data2.ravel()\n",
    "    data3 = data3.ravel()\n",
    "    data4 = data4.ravel()\n",
    "    data = [data1, data2, data3, data4]\n",
    "    corr = np.corrcoef(data,rowvar=True) \n",
    "    corr_data = pd.DataFrame(corr)\n",
    "    corr_data.to_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\相关性数据\\corr' + str(i) + '.csv', index=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\\\' + str(2016) + '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\\\' + str(2016) +  r'\\array\\country_array\\array'+str(100)+ '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\new_airports.csv', usecols=['iso_country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = np.unique(country)\n",
    "print(len(country)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(country)\n",
    "country = pd.DataFrame(country)\n",
    "country.to_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\country.csv', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\new_airports.csv', usecols=[2,3,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groups = file1.groupby(file1[u'iso_country'])\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "data1 = file1.groupby('iso_country')['latitude_deg','longitude_deg'].mean()\n",
    "data2 = data1.values\n",
    "time = np.zeros((len(data2), len(data2))) \n",
    "print(np.shape(time)) \n",
    "for i in range(len(data2)):\n",
    "    for j in range(len(data2)):\n",
    "        lng1, lat1, lng2, lat2 = map(radians, [data2[i][0], data2[i][1], data2[j][0], data2[j][1]])\n",
    "        dlon=lng2-lng1\n",
    "        dlat=lat2-lat1\n",
    "        a=sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2 \n",
    "        time[i][j]=2*asin(sqrt(a))*6371 / 900 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i, j "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\new_airports.csv', usecols=['iso_country'])\n",
    "name = np.unique(name)\n",
    "time = pd.DataFrame(time, columns = name)\n",
    "time.to_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\time.csv', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "file1 = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\new_airports.csv', usecols=['iata_code'])\n",
    "for j in range(60):\n",
    "    count = []\n",
    "    flight = np.zeros((len(file1), len(file1)))\n",
    "    file2 = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\2019\\basic data\\\\'+str(j)+'.csv', usecols=[0,1,2])\n",
    "    file2 = pd.DataFrame(file2)\n",
    "    for i in range(len(file2)):\n",
    "        take_off_city  = file2.loc[i][0]\n",
    "        down_city = file2.loc[i][1]\n",
    "        number = file2.loc[i][2]\n",
    "        #print(i)\n",
    "        a = file1[file1['iata_code'].isin([take_off_city])].index.tolist()\n",
    "        b = file1[file1['iata_code'].isin([down_city])].index.tolist()\n",
    "        if a == [] or b == []:\n",
    "            temp = file2.iloc[i]\n",
    "            count.append(temp)\n",
    "            continue;\n",
    "        else:\n",
    "            a = a[0]\n",
    "            b = b[0]\n",
    "        flight[a][b] += number\n",
    "    flight = pd.DataFrame(flight,columns = file1['iata_code'])\n",
    "    flight.to_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\2019\\array\\code_array\\code'+str(j)+'.csv',index=0)\n",
    "    count = pd.DataFrame(count)\n",
    "    count.to_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\2019\\array\\loss_data\\loss'+str(j)+'.csv',index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\new_airports.csv',usecols=[1,5]) \n",
    "name = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\new_airports.csv', usecols=['iso_country'])\n",
    "name = np.unique(name)\n",
    "group = country.groupby('iso_country')\n",
    "number = group.size().values\n",
    "for j in range(60):\n",
    "    print(j)\n",
    "    data1 = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\2019\\array\\code_array\\\\'+'code'+str(j)+'.csv').values\n",
    "    count = 0 \n",
    "    for i in range(len(number)):\n",
    "        if number[i] == 1 :\n",
    "            count += number[i]\n",
    "            continue;\n",
    "        if i == 0:\n",
    "            data1[:][0] += sum(data1[:][1:number[i]])\n",
    "            data1[0][:] += sum(data1[1:number[i]][:])\n",
    "        else:\n",
    "            data1[:][count] += sum(data1[:][count+1:count+number[i]])\n",
    "            data1[count][:] += sum(data1[count+1:count+number[i]][:])\n",
    "        count += number[i]\n",
    "\n",
    "    count = 0 \n",
    "    a = []\n",
    "    for i in range(len(number)):\n",
    "        if number[i] == 1 :\n",
    "            count += number[i]\n",
    "            continue; \n",
    "        a += list(range(count+1,count+number[i]))\n",
    "        count += number[i] \n",
    "    data = np.delete(data1, a, axis=1)\n",
    "    data = np.delete(data, a, axis=0)\n",
    "    print(np.shape(data))\n",
    "    data = pd.DataFrame(data ,columns = name)\n",
    "    data.to_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\2019\\array\\country_array\\\\'+'array'+str(j)+'.csv',index=0)\n",
    "    del a,data,data1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\Result.json',encoding='utf8') as fp:\n",
    "    json_data = json.load(fp)\n",
    "print('这是文件中的json数据：',json_data)\n",
    "print('这是读取到文件数据的数据类型：', type(json_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 3)\n"
     ]
    }
   ],
   "source": [
    "## 生成机场矩阵2019年\n",
    "import numpy as np \n",
    "## 读取按纬度排序的航空机场\n",
    "number = [2547, 1498, 252]\n",
    "name = ['North','Equator','South']\n",
    "file1 = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\new_airports_纬度.csv', usecols=['iata_code'])\n",
    "for j in range(366):\n",
    "    count1 = []\n",
    "    flight = np.zeros((len(file1), len(file1)))\n",
    "    file2 = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\year\\basic data\\\\'+str(j)+'.csv', usecols=[0,1,2])\n",
    "    file2 = pd.DataFrame(file2)\n",
    "    for i in range(len(file2)):\n",
    "        take_off_city  = file2.loc[i][0]\n",
    "        down_city = file2.loc[i][1]\n",
    "        number1 = file2.loc[i][2]\n",
    "        #print(i)\n",
    "        a = file1[file1['iata_code'].isin([take_off_city])].index.tolist()\n",
    "        b = file1[file1['iata_code'].isin([down_city])].index.tolist()\n",
    "        if a == [] or b == []:\n",
    "            temp = file2.iloc[i]\n",
    "            count1.append(temp)\n",
    "            continue;\n",
    "        else:\n",
    "            a = a[0]\n",
    "            b = b[0]\n",
    "        flight[a][b] += number1\n",
    "    data1 = flight\n",
    "    count = 0 \n",
    "    for i in range(len(number)):\n",
    "        if number[i] == 1 :\n",
    "            count += number[i]\n",
    "            continue;\n",
    "        if i == 0:\n",
    "            data1[:, 0] += sum(data1[:, 0:number[i]].T)\n",
    "            data1[0, :] += sum(data1[0:number[i], :])\n",
    "        else:\n",
    "            data1[:, count] += sum(data1[:, count:count+number[i]].T)\n",
    "            data1[count, :] += sum(data1[count:count+number[i], :])\n",
    "        count += number[i]\n",
    "    count = 0 \n",
    "    a = []\n",
    "    for i in range(len(number)):\n",
    "        if number[i] == 1 :\n",
    "            count += number[i]\n",
    "            continue; \n",
    "        a += list(range(count+1,count+number[i]))\n",
    "        count += number[i] \n",
    "    data = np.delete(data1, a, axis=1)\n",
    "    data = np.delete(data, a, axis=0)\n",
    "    print(np.shape(data))\n",
    "    data = pd.DataFrame(data ,columns = name)\n",
    "    data.to_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\year\\3_array\\\\'+'array' +str(j)+'.csv',index=0)\n",
    "    del a,data,data1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = [2547, 1498, 252]\n",
    "name = ['North','Equator','South']\n",
    "for j in range(60):\n",
    "    print(j)\n",
    "    data1 = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\2019\\array\\lat\\airports_array\\\\'+str(j)+'.csv').values\n",
    "    count = 0 \n",
    "    for i in range(len(number)):\n",
    "        if number[i] == 1 :\n",
    "            count += number[i]\n",
    "            continue;\n",
    "        if i == 0:\n",
    "            data1[:, 0] += sum(data1[:, 0:number[i]].T)\n",
    "            data1[0, :] += sum(data1[0:number[i], :])\n",
    "        else:\n",
    "            data1[:, count] += sum(data1[:, count:count+number[i]].T)\n",
    "            data1[count, :] += sum(data1[count:count+number[i], :])\n",
    "        count += number[i]\n",
    "    data2 = data1\n",
    "    count = 0 \n",
    "    a = []\n",
    "    for i in range(len(number)):\n",
    "        if number[i] == 1 :\n",
    "            count += number[i]\n",
    "            continue; \n",
    "        a += list(range(count+1,count+number[i]))\n",
    "        count += number[i] \n",
    "    data = np.delete(data1, a, axis=1)\n",
    "    data = np.delete(data, a, axis=0)\n",
    "    print(np.shape(data))\n",
    "    data = pd.DataFrame(data ,columns = name)\n",
    "    data.to_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\2019\\array\\lat\\3_array\\\\'+'array' +str(j)+'.csv',index=0)\n",
    "    del a,data,data1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "file1 = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\new_airports_234.csv', usecols=['iata_code'])\n",
    "for j in range(17):\n",
    "    count = []\n",
    "    flight = np.zeros((len(file1), len(file1)))\n",
    "    file2 = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\2019\\Olympic\\basic data\\\\'+str(j)+'.csv', usecols=[0,1,2])\n",
    "    file2 = pd.DataFrame(file2)\n",
    "    for i in range(len(file2)):\n",
    "        take_off_city  = file2.loc[i][0]\n",
    "        down_city = file2.loc[i][1]\n",
    "        number = file2.loc[i][2]\n",
    "        #print(i)\n",
    "        a = file1[file1['iata_code'].isin([take_off_city])].index.tolist()\n",
    "        b = file1[file1['iata_code'].isin([down_city])].index.tolist()\n",
    "        if a == [] or b == []:\n",
    "            temp = file2.iloc[i]\n",
    "            count.append(temp)\n",
    "            continue;\n",
    "        else:\n",
    "            a = a[0]\n",
    "            b = b[0]\n",
    "        flight[a][b] += number\n",
    "    flight = pd.DataFrame(flight,columns = file1['iata_code'])\n",
    "    flight.to_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\2019\\Olympic\\array\\\\'+str(j)+'.csv',index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(234, 234)\n",
      "1\n",
      "(234, 234)\n",
      "2\n",
      "(234, 234)\n",
      "3\n",
      "(234, 234)\n",
      "4\n",
      "(234, 234)\n",
      "5\n",
      "(234, 234)\n",
      "6\n",
      "(234, 234)\n",
      "7\n",
      "(234, 234)\n",
      "8\n",
      "(234, 234)\n",
      "9\n",
      "(234, 234)\n",
      "10\n",
      "(234, 234)\n",
      "11\n",
      "(234, 234)\n",
      "12\n",
      "(234, 234)\n",
      "13\n",
      "(234, 234)\n",
      "14\n",
      "(234, 234)\n",
      "15\n",
      "(234, 234)\n",
      "16\n",
      "(234, 234)\n"
     ]
    }
   ],
   "source": [
    "country = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\new_airports_234.csv',usecols=[1,5]) \n",
    "name = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\new_airports_234.csv', usecols=['iso_country'])\n",
    "name = np.unique(name)\n",
    "group = country.groupby('iso_country')\n",
    "number = group.size().values\n",
    "for j in range(17):\n",
    "    print(j) \n",
    "    data1 = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\2019\\Olympic\\array\\\\'+str(j)+'.csv').values\n",
    "    count = 0 \n",
    "    for i in range(len(number)):\n",
    "        if number[i] == 1 :\n",
    "            count += number[i]\n",
    "            continue;\n",
    "        if i == 0:\n",
    "            data1[:, 0] += sum(data1[:, 0:number[i]].T)\n",
    "            data1[0, :] += sum(data1[0:number[i], :])\n",
    "        else:\n",
    "            data1[:, count] += sum(data1[:, count:count+number[i]].T)\n",
    "            data1[count, :] += sum(data1[count:count+number[i], :])\n",
    "        count += number[i]\n",
    "    data2 = data1\n",
    "    count = 0 \n",
    "    a = []\n",
    "    for i in range(len(number)):\n",
    "        if number[i] == 1 :\n",
    "            count += number[i]\n",
    "            continue; \n",
    "        a += list(range(count+1,count+number[i]))\n",
    "        count += number[i] \n",
    "    data = np.delete(data1, a, axis=1)\n",
    "    data = np.delete(data, a, axis=0)\n",
    "    print(np.shape(data))\n",
    "    data = pd.DataFrame(data ,columns = name)\n",
    "    data.to_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\2019\\Olympic\\country_array\\\\'+'array'+str(j)+'.csv',index=0)\n",
    "    del a,data,data1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "file1 = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\new_airports_234.csv', usecols=['iata_code'])\n",
    "country = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\new_airports_234.csv',usecols=[1,5]) \n",
    "name = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\new_airports_234.csv', usecols=['iso_country'])\n",
    "name = np.unique(name)\n",
    "group = country.groupby('iso_country')\n",
    "number = group.size().values\n",
    "for j in range(1):\n",
    "    count1 = []\n",
    "    flight = np.zeros((len(file1), len(file1)))\n",
    "    file2 = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\2019\\date series\\\\'+str(j)+'.csv', usecols=[0,1,2])\n",
    "    file2 = pd.DataFrame(file2)\n",
    "    for i in range(len(file2)):\n",
    "        take_off_city  = file2.loc[i][0]\n",
    "        down_city = file2.loc[i][1]\n",
    "        number1 = file2.loc[i][2]\n",
    "        #print(i)\n",
    "        a = file1[file1['iata_code'].isin([take_off_city])].index.tolist()\n",
    "        b = file1[file1['iata_code'].isin([down_city])].index.tolist()\n",
    "        if a == [] or b == []:\n",
    "            temp = file2.iloc[i]\n",
    "            count1.append(temp)\n",
    "            continue;\n",
    "        else:\n",
    "            a = a[0]\n",
    "            b = b[0]\n",
    "        flight[a][b] += number1\n",
    "        \n",
    "    data1 = flight\n",
    "    count = 0 \n",
    "    for i in range(len(number)):\n",
    "        if number[i] == 1 :\n",
    "            count += number[i]\n",
    "            continue;\n",
    "        if i == 0:\n",
    "            data1[:, 0] += sum(data1[:, 0:number[i]].T)\n",
    "            data1[0, :] += sum(data1[0:number[i], :])\n",
    "        else:\n",
    "            data1[:, count] += sum(data1[:, count:count+number[i]].T)\n",
    "            data1[count, :] += sum(data1[count:count+number[i], :])\n",
    "        count += number[i]\n",
    "    data2 = data1\n",
    "    count = 0 \n",
    "    a = []\n",
    "    for i in range(len(number)):\n",
    "        if number[i] == 1 :\n",
    "            count += number[i]\n",
    "            continue; \n",
    "        a += list(range(count+1,count+number[i]))\n",
    "        count += number[i] \n",
    "    data = np.delete(data1, a, axis=1)\n",
    "    data = np.delete(data, a, axis=0)\n",
    "    print(np.shape(data))\n",
    "    data = pd.DataFrame(data ,columns = name)\n",
    "    data.to_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\2019\\array\\country_array\\\\'+'array'+str(j)+'.csv',index=0)\n",
    "    del a,data,data1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(234, 234)\n",
      "1\n",
      "(234, 234)\n",
      "2\n",
      "(234, 234)\n",
      "3\n",
      "(234, 234)\n",
      "4\n",
      "(234, 234)\n",
      "5\n",
      "(234, 234)\n",
      "6\n",
      "(234, 234)\n",
      "7\n",
      "(234, 234)\n",
      "8\n",
      "(234, 234)\n",
      "9\n",
      "(234, 234)\n",
      "10\n",
      "(234, 234)\n",
      "11\n",
      "(234, 234)\n",
      "12\n",
      "(234, 234)\n",
      "13\n",
      "(234, 234)\n",
      "14\n",
      "(234, 234)\n",
      "15\n",
      "(234, 234)\n",
      "16\n",
      "(234, 234)\n",
      "17\n",
      "(234, 234)\n",
      "18\n",
      "(234, 234)\n",
      "19\n",
      "(234, 234)\n",
      "20\n",
      "(234, 234)\n",
      "21\n",
      "(234, 234)\n",
      "22\n",
      "(234, 234)\n",
      "23\n",
      "(234, 234)\n",
      "24\n",
      "(234, 234)\n",
      "25\n",
      "(234, 234)\n",
      "26\n",
      "(234, 234)\n",
      "27\n",
      "(234, 234)\n",
      "28\n",
      "(234, 234)\n",
      "29\n",
      "(234, 234)\n",
      "30\n",
      "(234, 234)\n",
      "31\n",
      "(234, 234)\n",
      "32\n",
      "(234, 234)\n",
      "33\n",
      "(234, 234)\n",
      "34\n",
      "(234, 234)\n",
      "35\n",
      "(234, 234)\n",
      "36\n",
      "(234, 234)\n",
      "37\n",
      "(234, 234)\n",
      "38\n",
      "(234, 234)\n",
      "39\n",
      "(234, 234)\n",
      "40\n",
      "(234, 234)\n",
      "41\n",
      "(234, 234)\n",
      "42\n",
      "(234, 234)\n",
      "43\n",
      "(234, 234)\n",
      "44\n",
      "(234, 234)\n",
      "45\n",
      "(234, 234)\n",
      "46\n",
      "(234, 234)\n",
      "47\n",
      "(234, 234)\n",
      "48\n",
      "(234, 234)\n",
      "49\n",
      "(234, 234)\n",
      "50\n",
      "(234, 234)\n",
      "51\n",
      "(234, 234)\n",
      "52\n",
      "(234, 234)\n",
      "53\n",
      "(234, 234)\n",
      "54\n",
      "(234, 234)\n",
      "55\n",
      "(234, 234)\n",
      "56\n",
      "(234, 234)\n",
      "57\n",
      "(234, 234)\n",
      "58\n",
      "(234, 234)\n",
      "59\n",
      "(234, 234)\n"
     ]
    }
   ],
   "source": [
    "country = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\new_airports_234.csv',usecols=[1,5]) \n",
    "name = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\new_airports_234.csv', usecols=['iso_country'])\n",
    "name = np.unique(name)\n",
    "group = country.groupby('iso_country')\n",
    "number = group.size().values\n",
    "for j in range(60):\n",
    "    print(j)\n",
    "    data1 = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\2019\\array\\code_array\\\\'+str(j)+'.csv').values\n",
    "    count = 0 \n",
    "    for i in range(len(number)):\n",
    "        if number[i] == 1 :\n",
    "            count += number[i]\n",
    "            continue;\n",
    "        if i == 0:\n",
    "            data1[:, 0] += sum(data1[:, 0:number[i]].T)\n",
    "            data1[0, :] += sum(data1[0:number[i], :])\n",
    "        else:\n",
    "            data1[:, count] += sum(data1[:, count:count+number[i]].T)\n",
    "            data1[count, :] += sum(data1[count:count+number[i], :])\n",
    "        count += number[i]\n",
    "    data2 = data1\n",
    "    count = 0 \n",
    "    a = []\n",
    "    for i in range(len(number)):\n",
    "        if number[i] == 1 :\n",
    "            count += number[i]\n",
    "            continue; \n",
    "        a += list(range(count+1,count+number[i]))\n",
    "        count += number[i] \n",
    "    data = np.delete(data1, a, axis=1)\n",
    "    data = np.delete(data, a, axis=0)\n",
    "    print(np.shape(data))\n",
    "    data = pd.DataFrame(data ,columns = name)\n",
    "    data.to_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\2019\\array\\country_array\\\\'+'array'+str(j)+'.csv',index=0)\n",
    "    del a,data,data1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\new_airports_234.csv',usecols=[1,5]) \n",
    "name = pd.read_csv(r'F:\\项目\\新冠肺炎\\参考论文\\2016_flight\\newdata\\new_airports_234.csv', usecols=['iso_country'])\n",
    "name = np.unique(name)\n",
    "group = country.groupby('iso_country')\n",
    "number = group.size().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AE', 'AF', 'AG', 'AI', 'AL', 'AM', 'AO', 'AR', 'AS', 'AT', 'AU',\n",
       "       'AW', 'AZ', 'BA', 'BB', 'BD', 'BE', 'BF', 'BG', 'BH', 'BI', 'BJ',\n",
       "       'BL', 'BM', 'BN', 'BO', 'BQ', 'BR', 'BS', 'BT', 'BW', 'BY', 'BZ',\n",
       "       'CA', 'CC', 'CD', 'CF', 'CG', 'CH', 'CI', 'CK', 'CL', 'CM', 'CN',\n",
       "       'CO', 'CR', 'CU', 'CV', 'CW', 'CX', 'CY', 'CZ', 'DE', 'DJ', 'DK',\n",
       "       'DM', 'DO', 'DZ', 'EC', 'EE', 'EG', 'EH', 'ER', 'ES', 'ET', 'FI',\n",
       "       'FJ', 'FK', 'FM', 'FO', 'FR', 'GA', 'GB', 'GD', 'GE', 'GF', 'GG',\n",
       "       'GH', 'GI', 'GL', 'GM', 'GN', 'GP', 'GQ', 'GR', 'GT', 'GU', 'GW',\n",
       "       'GY', 'HK', 'HN', 'HR', 'HT', 'HU', 'ID', 'IE', 'IL', 'IM', 'IN',\n",
       "       'IQ', 'IR', 'IS', 'IT', 'JE', 'JM', 'JO', 'JP', 'JPTK', 'KE', 'KG',\n",
       "       'KH', 'KI', 'KM', 'KN', 'KP', 'KR', 'KW', 'KY', 'KZ', 'LA', 'LB',\n",
       "       'LC', 'LK', 'LR', 'LS', 'LT', 'LU', 'LV', 'LY', 'MA', 'MC', 'MD',\n",
       "       'ME', 'MF', 'MG', 'MH', 'MK', 'ML', 'MM', 'MN', 'MO', 'MP', 'MQ',\n",
       "       'MR', 'MS', 'MT', 'MU', 'MV', 'MW', 'MX', 'MY', 'MZ', 'NA_', 'NE',\n",
       "       'NF', 'NG', 'NI', 'NL', 'NO', 'NP', 'NR', 'NU', 'NZ', 'OM', 'PA',\n",
       "       'PE', 'PF', 'PG', 'PH', 'PK', 'PL', 'PM', 'PR', 'PT', 'PW', 'PY',\n",
       "       'QA', 'RE', 'RO', 'RS', 'RU', 'RW', 'SA', 'SB', 'SC', 'SD', 'SE',\n",
       "       'SG', 'SH', 'SI', 'SK', 'SL', 'SN', 'SO', 'SR', 'SS', 'ST', 'SV',\n",
       "       'SX', 'SY', 'SZ', 'TC', 'TD', 'TG', 'TH', 'TJ', 'TL', 'TM', 'TN',\n",
       "       'TO', 'TR', 'TT', 'TV', 'TW', 'TZ', 'UA', 'UG', 'US', 'UY', 'UZ',\n",
       "       'VC', 'VE', 'VG', 'VI', 'VN', 'VU', 'WF', 'WS', 'XK', 'YE', 'YT',\n",
       "       'ZA', 'ZM', 'ZW'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
